<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Week 11 Handout: Quality Assurance (Remainder)</title>
    <link rel="stylesheet" href="..\..\markbind\css\bootstrap.min.css">
    <link rel="stylesheet" href="..\..\markbind\css\github.min.css">
    <link rel="stylesheet" href="..\..\markbind\css\markbind.css">
</head>
<body>
<div id="app" class="container-fluid">
    <link rel="stylesheet" href="/website/book/css/textbook.css">
<div class="website-content">
  <div id="main">
    <p><sub><span class="dimmed">... continuing from the Testing chapter</span></sub></p>
    <div>
      <h3 id="unit-testing">Unit Testing</h3>
      <div>
        <div>
          <h4 id="what-one">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0031-20e3.png"></h4>
        </div>
        <div>
          <p><strong><em>Unit testing</em> : testing individual units (methods, classes, subsystems, ...) to ensure each piece works correctly.</strong></p>
          <p>In OOP code, it is common to write one or more unit tests for each public method of a class.</p>
          <tip-box>
            <p>üì¶ Here are the code skeletons for a <code>Foo</code> class containing two methods and a <code>FooTest</code> class that contains unit tests for those two methods.</p>
            <tabs>
            
              <tab header="Java">
                <div>
                  <pre><code class="hljs java"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Foo</span></span>{
    <span class="hljs-function">String <span class="hljs-title">read</span><span class="hljs-params">()</span></span>{
        <span class="hljs-comment">//...</span>
    }
    
    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">write</span><span class="hljs-params">(String input)</span></span>{
        <span class="hljs-comment">//...</span>
    }
    
}

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FooTest</span></span>{
    
    <span class="hljs-meta">@Test</span>
    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">read</span><span class="hljs-params">()</span></span>{
        <span class="hljs-comment">//a unit test for Foo#read() method</span>
    }
    
    <span class="hljs-meta">@Test</span>
    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">write_emptyInput_exceptionThrown</span><span class="hljs-params">()</span></span>{
        <span class="hljs-comment">//a unit tests for Foo#write(String) method</span>
    }  
    
    <span class="hljs-meta">@Test</span>
    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">write_normalInput_writtenCorrectly</span><span class="hljs-params">()</span></span>{
        <span class="hljs-comment">//another unit tests for Foo#write(String) method</span>
    }
}
</code></pre>
                </div>
              </tab>
            
              <tab header="Python">
                <div>
                  <pre><code class="hljs python"><span class="hljs-keyword">import</span> unittest

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Foo</span>:</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">read</span><span class="hljs-params">(self)</span>:</span>
      <span class="hljs-comment"># ...</span>
  
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">write</span><span class="hljs-params">(self, input)</span>:</span>
      <span class="hljs-comment"># ...</span>


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FooTest</span><span class="hljs-params">(unittest.TestCase)</span>:</span>
  
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_read</span><span class="hljs-params">(sefl)</span>:</span>
      <span class="hljs-comment"># a unit test for read() method</span>
  
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_write_emptyIntput_ignored</span><span class="hljs-params">(self)</span>:</span>
      <span class="hljs-comment"># a unit tests for write(string) method</span>
  
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_write_normalInput_writtenCorrectly</span><span class="hljs-params">(self)</span>:</span>
      <span class="hljs-comment"># another unit tests for write(string) method</span>
</code></pre>
                </div>
              </tab>
            </tabs>
            <hr>
          </tip-box>
        </div>
      </div>
      <h3 id="integration-testing">Integration Testing</h3>
      <div>
        <div>
          <h4 id="what-one-2">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0031-20e3.png"></h4>
        </div>
        <div>
          <p><strong><em>Integration testing</em> : testing whether different parts of the software <em>work together</em> (i.e. integrates) as expected.</strong> Integration tests aim to discover bugs in the 'glue code' related to how components interact
            with each other. These bugs are often the result of misunderstanding of what the parts are supposed to do vs what the parts are actually doing.</p>
          <tip-box>
            <p>üì¶ Suppose a class <code>Car</code> users classes <code>Engine</code> and <code>Wheel</code>. If the <code>Car</code> class assumed a <code>Wheel</code> can support 200 mph speed but the actual <code>Wheel</code> can only support 150 mph,
              it is the integration test that is supposed to uncover this discrepancy.</p>
          </tip-box>
        </div>
      </div>
      <h3 id="system-testing">System Testing</h3>
      <div>
        <div>
          <h4 id="what-one-3">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0031-20e3.png"></h4>
        </div>
        <div>
          <p><strong><em>System testing</em>: take the <em>whole system</em> and test it <em>against the system specification</em>.</strong></p>
          <p>System testing is typically done by a testing team (also called a QA team).</p>
          <p><strong>System test cases are based on the specified external behavior of the system.</strong> Sometimes, system tests go beyond the bounds defined in the specification. This is useful when testing that the system fails 'gracefully' having pushed
            beyond its limits.</p>
          <tip-box>
            <p>üì¶ Suppose the SUT is a browser supposedly capable of handling web pages containing up to 5000 characters. Given below is a test case to test if the SUT fails gracefully if pushed beyond its limits.</p>
            <pre class="hljs"><code>Test case: load a web page that is too big
* Input: load a web page containing more than 5000 characters. 
* Expected behavior: abort the loading of the page and show a meaningful error message. 
</code></pre>
            <p>This test case would fail if the browser attempted to load the large file anyway and crashed.</p>
          </tip-box>
          <p><strong>System testing includes testing against non-functional requirements too.</strong> Here are some examples.</p>
          <ul>
            <li><em>Performance testing</em> ‚Äì to ensure the system responds quickly.</li>
            <li><em>Load testing</em> (also called <em>stress testing</em> or <em>scalability testing</em>) ‚Äì to ensure the system can work under heavy load.</li>
            <li><em>Security testing</em> ‚Äì to test how secure the system is.</li>
            <li><em>Compatibility testing, interoperability testing</em> ‚Äì to check whether the system can work with other systems.</li>
            <li><em>Usability testing</em> ‚Äì to test how easy it is to use the system.</li>
            <li><em>Portability testing</em> ‚Äì to test whether the system works on different platforms.</li>
          </ul>
        </div>
      </div>
      <h3 id="alpha-beta-testing">Alpha-Beta Testing</h3>
      <div>
        <div>
          <h4 id="what-three">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0033-20e3.png"></h4>
        </div>
        <div>
          <p><strong><em>Alpha testing</em> is performed by the users, under controlled conditions set by the software development team.</strong></p>
          <p><strong><em>Beta testing</em> is performed by a selected subset of target users of the system in their natural work setting.</strong></p>
          <p>An <em>open beta release</em> is the release of not-yet-production-quality-but-almost-there software to the general population. For example, Google‚Äôs Gmail was in 'beta' for many years before the label was finally removed.</p>
        </div>
      </div>
      <p style="page-break-after: always;">&nbsp;</p>
      <h3 id="developer-testing">Developer Testing</h3>
      <div>
        <div>
          <h4 id="what-two">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p><strong><em>Developer testing</em> is the testing done by the developers themselves</strong> as opposed to professional testers or end-users.</p>
        </div>
      </div>
      <div>
        <div>
          <h4 id="why-two">Why <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p><strong>Delaying testing until the full product is complete has a number of disadvantages:</strong></p>
          <ul>
            <li><strong>Locating the cause of such a test case failure is difficult due to a large search space;</strong> in a large system, the search space could be millions of lines of code, written by hundreds of developers! The failure may also be due
              to multiple inter-related bugs.</li>
            <li><strong>Fixing a bug found during such testing could result in major rework</strong>, especially if the bug originated during the design or during requirements specification <span class="dimmed">i.e. a faulty design or faulty requirements</span>.</li>
            <li><strong>One bug might 'hide' other bugs</strong>, which could emerge only after the first bug is fixed.</li>
            <li><strong>The delivery may have to be delayed</strong> if too many bugs were found during testing.</li>
          </ul>
          <p><strong>Therefore, it is better to do early testing</strong>, as hinted by the popular rule of thumb given below, also illustrated by the graph below it.</p>
          <blockquote>
            <p>The earlier a bug is found, the easier and cheaper to have it fixed.</p>
          </blockquote>
          <img src="/website/book/testing/testingTypes/developerTesting/why/images/diagram.png" height="180">
          <p></p>
          <p>Such early testing of partially developed software is usually, and by necessity, done by the developers themselves i.e. developer testing.</p>
        </div>
      </div>
      <h3 id="acceptance-testing">Acceptance Testing</h3>
      <div>
        <div>
          <h4 id="what-one-4">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0031-20e3.png"></h4>
        </div>
        <div>
          <p><strong><em>Acceptance testing</em> (aka <em>User Acceptance Testing (UAT)</em>): test the delivered system to ensure it meets the user requirements.</strong></p>
          <p>Acceptance tests give an assurance to the customer that the system does what it is intended to do. Acceptance test cases are often defined at the beginning of the project, usually based on the use case specification. Successful completion of
            UAT is often a prerequisite to the project sign-off.</p>
        </div>
      </div>
      <div>
        <div>
          <h4 id="acceptance-vs-system-testing-two">Acceptance vs System Testing <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p>Acceptance testing comes after system testing. Similar to system testing, acceptance testing involves testing the whole system.</p>
          <p>Some differences between system testing and acceptance testing:</p>
          <table class="markbind-table table table-bordered table-striped">
            <thead>
              <tr>
                <th style="text-align:left">System Testing</th>
                <th style="text-align:left">Acceptance Testing</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left">Done against the system specification</td>
                <td style="text-align:left">Done against the requirements specification</td>
              </tr>
              <tr>
                <td style="text-align:left">Done by testers of the project team</td>
                <td style="text-align:left">Done by a team that represents the customer</td>
              </tr>
              <tr>
                <td style="text-align:left">Done on the development environment or a test bed</td>
                <td style="text-align:left">Done on the deployment site or on a close simulation of the deployment site</td>
              </tr>
              <tr>
                <td style="text-align:left">Both negative and positive test cases</td>
                <td style="text-align:left">More focus on positive test cases</td>
              </tr>
            </tbody>
          </table>
          <p><span class="dimmed">Note: <em>negative</em> test cases: cases where the SUT is not expected to work normally e.g. incorrect inputs; <em>positive</em> test cases: cases where the SUT is expected to work normally</span></p>
          <tip-box>
            <p><strong>Requirement Specification vs System Specification</strong></p>
            <p>The requirement specification need not be the same as the system specification. Some example differences:</p>
            <table class="markbind-table table table-bordered table-striped">
              <thead>
                <tr>
                  <th style="text-align:left">Requirements Specification</th>
                  <th style="text-align:left">System Specification</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:left">limited to how the system behaves in normal working conditions</td>
                  <td style="text-align:left">can also include details on how it will fail gracefully when pushed beyond limits, how to recover, etc. specification</td>
                </tr>
                <tr>
                  <td style="text-align:left">written in terms of problems that need to be solved (e.g. provide a method to locate an email quickly)</td>
                  <td style="text-align:left">written in terms of how the system solve those problems (e.g. explain the email search feature)</td>
                </tr>
                <tr>
                  <td style="text-align:left">specifies the interface available for intended end-users</td>
                  <td style="text-align:left">could contain additional APIs not available for end-users (for the use of developers/testers)</td>
                </tr>
              </tbody>
            </table>
            <p>However, <strong>in many cases one document serves as both a requirement specification and a system specification.</strong></p>
          </tip-box>
          <p><strong>Passing system tests does not necessarily mean passing acceptance testing.</strong> Some examples:</p>
          <ul>
            <li>The system might work on the testbed environments but might not work the same way in the deployment environment, due to subtle differences between the two environments.</li>
            <li>The system might conform to the system specification but could fail to solve the problem it was supposed to solve for the user, due to flaws in the system design.</li>
          </ul>
        </div>
      </div>
      <h3 id="exploratory-vs-scripted-testing">Exploratory vs Scripted Testing</h3>
      <div>
        <div>
          <h4 id="what-two-2">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p><strong>Here are two alternative approaches to testing a software: <em>Scripted</em> testing and <em>Exploratory</em> testing</strong></p>
          <ol>
            <li>
              <p><strong>Scripted testing:</strong> First write a set of test cases based on the expected behavior of the SUT, and then perform testing based on that set of test cases.</p>
            </li>
            <li>
              <p><strong>Exploratory testing:</strong> Devise test cases on-the-fly, creating new test cases based on the results of the past test cases.</p>
            </li>
          </ol>
          <p>Exploratory testing is ‚Äòthe simultaneous learning, test design, and test execution‚Äô
            <trigger trigger="click" for="modal:exploratoryWhat-bach-et-explained">[source: bach-et-explained]</trigger> whereby the nature of the follow-up test case is decided based on the behavior of the previous test cases. In other words, running the system and trying out various operations. It is called <em>exploratory testing</em>            because testing is driven by observations during testing. Exploratory testing usually starts with areas identified as error-prone, based on the tester‚Äôs past experience with similar systems. One tends to conduct more tests for those operations
            where more faults are found.</p>
          <tip-box>
            <p>üì¶ Here is an example thought process behind a segment of an exploratory testing session:</p>
            <blockquote>
              <p>‚ÄúHmm... looks like feature x is broken. This usually means feature n and k could be broken too; we need to look at them soon. But before that, let us give a good test run to feature y because users can still use the product if feature y
                works, even if x doesn‚Äôt work. Now, if feature y doesn‚Äôt work 100%, we have a major problem and this has to be made known to the development team sooner rather than later...‚Äù</p>
            </blockquote>
          </tip-box>
          <tip-box>
            <p>üí° <strong>Exploratory testing is also known as <em>reactive testing, error guessing technique, attack-based testing,</em> and <em>bug hunting</em>.</strong></p>
          </tip-box>
          <modal id="modal:exploratoryWhat-bach-et-explained" title="bach-et-explained :mag:">
            <div>
              <p><a href="http://www.satisfice.com/articles/et-article.pdf"><strong>Exploratory Testing Explained</strong></a>, an online article by <a href="http://www.satisfice.com/aboutjames.shtml">James Bach</a> -- James Bach is an industry thought leader
                in software testing).</p>
            </div>
          </modal>
        </div>
      </div>
      <div>
        <div>
          <h4 id="when-three">When <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0033-20e3.png"></h4>
        </div>
        <div>
          <p>Which approach is better ‚Äì <strong>scripted or exploratory? A mix is better.</strong></p>
          <p><strong>The success of exploratory testing depends on the tester‚Äôs prior experience and intuition.</strong> Exploratory testing should be done by experienced testers, using a clear strategy/plan/framework. Ad-hoc exploratory testing by unskilled
            or inexperienced testers without a clear strategy is not recommended for real-world non-trivial systems. While <strong>exploratory testing may allow us to detect some problems in a relatively short time, it is not prudent to use exploratory testing as the sole means of testing a critical system</strong>.</p>
          <p><strong>Scripted testing is more systematic, and hence, likely to discover more bugs given sufficient time</strong>, while exploratory testing would aid in quick error discovery, especially if the tester has a lot of experience in testing similar
            systems.</p>
          <blockquote>
            <p>In some contexts, you will achieve your testing mission better through a more scripted approach; in other contexts, your mission will benefit more from the ability to create and improve tests as you execute them. I find that most situations
              benefit from a mix of scripted and exploratory approaches. --
              <trigger trigger="click" for="modal:ExploratoryWhen-bach-et-explained">[source: bach-et-explained]</trigger>
            </p>
          </blockquote>
          <modal id="modal:ExploratoryWhen-bach-et-explained" title="bach-et-explained :mag:">
            <div>
              <p><a href="http://www.satisfice.com/articles/et-article.pdf"><strong>Exploratory Testing Explained</strong></a>, an online article by <a href="http://www.satisfice.com/aboutjames.shtml">James Bach</a> -- James Bach is an industry thought leader
                in software testing).</p>
            </div>
          </modal>
        </div>
      </div>
      <p style="page-break-after: always;">&nbsp;</p>
      <h1 id="test-case-design">Test Case Design</h1>
      <h2 id="introduction">Introduction</h2>
      <div>
        <div>
          <h4 id="what-two-3">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p><strong>Except for trivial <tooltip content="Software Under Test">SUTs</tooltip>, <tooltip content="testing all possible cases">exhaustive testing</tooltip> is not practical</strong> because such testing often requires a massive/infinite number
            of test cases.</p>
          <tip-box>
            <p>üì¶ Consider the test cases for adding a string object to a
              <tooltip content="Java: `ArrayList`,<br>Python: `list`">collection</tooltip>:</p>
            <ul>
              <li>Add an item to an empty collection.</li>
              <li>Add an item when there is one item in the collection.</li>
              <li>Add an item when there are 2, 3, .... n items in the collection.</li>
              <li>Add an item that has an English, a French, a Spanish, ... word.</li>
              <li>Add an item that is the same as an existing item.</li>
              <li>Add an item immediately after adding another item.</li>
              <li>Add an item immediately after system startup.</li>
              <li>...</li>
            </ul>
            <p>Exhaustive testing of this operation can take many more test cases.</p>
          </tip-box>
          <blockquote>
            <p>Program testing can be used to show the presence of bugs, but never to show their absence!<br>
              <sub>--Edsger Dijkstra</sub></p>
          </blockquote>
          <div id="e-and-e">
            <p><strong>Every test case adds to the cost of testing.</strong> In some systems, a single test case can cost thousands of dollars <span class="dimmed">¬†e.g. on-field testing of flight-control software</span>. Therefore, <strong>test cases need to be designed to make the best use of testing resources.</strong>              In particular:</p>
            <ul>
              <li>
                <p><strong>Testing should be <em>effective</em></strong> i.e., it finds a high percentage of existing bugs <span class="dimmed">e.g., a set of test cases that finds 60 defects is more effective than a set that finds only 30 defects in the same system</span>.</p>
              </li>
              <li>
                <p><strong>Testing should be <em>efficient</em></strong> i.e., it has a high rate of success (bugs found/test cases) <span class="dimmed">a set of 20 test cases that finds 8 defects is more efficient than another set of 40 test cases that finds the same 8 defects</span>.</p>
              </li>
            </ul>
            <p><strong>For testing to be <tooltip content="Efficient and Effective">E&amp;E</tooltip>, each new test we add should be targeting a potential fault that is not already targeted by existing test cases.</strong> There are test case design techniques
              that can help us improve E&amp;E of testing.</p>
          </div>
        </div>
      </div>
      <div>
        <div>
          <h4 id="black-box-vs-glass-box-two">Black Box vs Glass Box <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p><strong>Test case design can be of three types, based on how much of SUT internal details are considered when designing test cases:</strong></p>
          <ul>
            <li>
              <p><strong><em>Black-box</em> (aka <em>specification-based or responsibility-based</em>) approach</strong>: test cases are designed exclusively based on the SUT‚Äôs specified external behavior.</p>
            </li>
            <li>
              <p><strong><em>White-box</em> (aka <em>glass-box or structured or implementation-based</em>) approach</strong>: test cases are designed based on what is known about the SUT‚Äôs implementation, i.e. the code.</p>
            </li>
            <li>
              <p><strong><em>Gray-box</em> approach</strong>: test case design uses <em>some</em> important information about the implementation. For example, if the implementation of a sort operation uses different algorithms to sort lists shorter than
                1000 items and lists longer than 1000 items, more meaningful test cases can then be added to verify the correctness of both algorithms.</p>
            </li>
          </ul>
          <panel type="seamless" header=":tv: %%Black-box and white-box testing%%">
            <p><sub>Note: these videos are from the <a href="https://www.udacity.com/course/software-development-process--ud805">Udacity course <em>Software Development Process</em> by Georgia Tech</a></sub></p>
            <tabs>
            
              <tab header=":tv: Black-box vs White-box testing">
                <div class="block-embed block-embed-service-youtube"><iframe type="text/html" src="//www.youtube.com/embed/jRwwb7iaRsU" frameborder="0" width="640" height="390" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen></iframe></div>
                <p>
                  <hr>
                </p>
              </tab>
            
              <tab header=":tv: Black-box testing example">
                <div class="block-embed block-embed-service-youtube"><iframe type="text/html" src="//www.youtube.com/embed/6pbB37nFUZw" frameborder="0" width="640" height="390" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen></iframe></div>
                <p>
                  <hr>
                </p>
              </tab>
            
              <tab header=":tv: White-box testing example">
                <div class="block-embed block-embed-service-youtube"><iframe type="text/html" src="//www.youtube.com/embed/KIAkoae6_jE" frameborder="0" width="640" height="390" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen></iframe></div>
                <p>
                  <hr>
                </p>
              </tab>
            </tabs>
          </panel>
        </div>
      </div>
      <h2 id="equivalence-partitions">Equivalence Partitions</h2>
      <div>
        <div>
          <h4 id="what-two-4">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p>Consider the testing of the following operation.</p>
          <tip-box>
            <div id="isValidMonth">
              <p><code>isValidMonth(m)</code> : returns <code>true</code> if <code>m</code> (and <code>int</code>) is in the range [1..12]</p>
            </div>
          </tip-box>
          <p>It is inefficient and impractical to test this method for all integer values <code>[-MIN_INT to MAX_INT]</code>. Fortunately, there is no need to test all possible input values. For example, if the input value <code>233</code> failed to produce
            the correct result, the input <code>234</code> is likely to fail too; there is no need to test both.</p>
          <p>In general, <strong>most SUTs do not treat each input in a unique way. Instead, they process all possible inputs in a small number of distinct ways.</strong> That means a range of inputs is treated the same way inside the SUT.
            <strong><em>Equivalence partitioning (EP)</em> is a test case design technique that uses the above observation to improve the E&amp;E of testing.</strong></p>
          <tip-box type="definition">
            <div>
              <p><strong>Equivalence partition (aka equivalence class)</strong>: A group of test inputs that are likely to be processed by the SUT in the same way.</p>
            </div>
          </tip-box>
          <p><strong>By dividing possible inputs into equivalence partitions we can,</strong></p>
          <ul>
            <li><strong>avoid testing too many inputs from one partition.</strong> Testing too many inputs from the same partition is unlikely to find new bugs. This increases the efficiency of testing by reducing redundant test cases.</li>
            <li><strong>ensure all partitions are tested.</strong> Missing partitions can result in bugs going unnoticed. This increases the effectiveness of testing by increasing the chance of finding bugs.</li>
          </ul>
        </div>
      </div>
      <div>
        <div>
          <h4 id="basic-two">Basic <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p><strong>Equivalence partitions (EPs) are usually derived from the specifications of the SUT.</strong></p>
          <tip-box>
            <p>üì¶ These could be EPs for the
              <trigger for="pop:epBasic-isValidMonth">isValidMonth</trigger> example:</p>
            <ul>
              <li>[MIN_INT ... 0] : <strong>below</strong> the range that produces <code>true</code></li>
              <li>[1 ‚Ä¶ 12] : the range that produces <code>true</code></li>
              <li>[13 ‚Ä¶ MAX_INT] : <strong>above</strong> the range that produces <code>true</code></li>
            </ul>
          </tip-box>
          <popover id="pop:epBasic-isValidMonth" title="`isValidMonth`" placement="top">
          
            <div slot="content">
              <div>
                <p><code>isValidMonth(m)</code> : returns <code>true</code> if <code>m</code> (and <code>int</code>) is in the range [1..12]</p>
              </div>
            </div>
          </popover>
          <p>When the SUT has multiple inputs, you should identify EPs for each input.</p>
          <tip-box>
            <p>üì¶ Consider the method <code>duplicate(String s, int n): String</code> which returns a <code>String</code> that contains <code>s</code> repeated <code>n</code> times.</p>
            <p>Example EPs for <code>s</code>:</p>
            <ul>
              <li>zero-length strings</li>
              <li>string containing whitespaces</li>
              <li>...</li>
            </ul>
            <p>Example EPs for <code>n</code>:</p>
            <ul>
              <li><code>0</code></li>
              <li>negative values</li>
              <li>...</li>
            </ul>
          </tip-box>
          <p>An EP may not have adjacent values.</p>
          <tip-box>
            <p>üì¶ Consider the method <code>isPrime(int i): boolean</code> that returns true if <code>i</code> is a prime number.</p>
            <p>EPs for <code>i</code>:</p>
            <ul>
              <li>prime numbers</li>
              <li>non-prime numbers</li>
            </ul>
          </tip-box>
          <p>Some inputs have only a small number of possible values and a potentially unique behavior for each value. In those cases we have to consider each value as a partition by itself.</p>
          <tip-box>
            <p>üì¶ Consider the method <code>showStatusMessage(GameStatus s): String</code> that returns a unique <code>String</code> for each of the possible value of s (<code>GameStatus</code> is an <code>enum</code>). In this case, each possible value
              for <code>s</code> will have to be considered as a partition.</p>
          </tip-box>
          <p>Note that the EP technique is merely a heuristic and not an exact science, especially when applied manually (as opposed to using an automated program analysis tool to derive EPs). The partitions derived depend on how one ‚Äòspeculates‚Äô the SUT
            to behave internally. Applying EP under a glass-box or gray-box approach can yield more precise partitions.</p>
          <tip-box>
            <p>üì¶ Consider the method EPs given above for the <code>isValidMonth</code>. A different tester might use these EPs instead:</p>
            <ul>
              <li>[1 ‚Ä¶ 12] : the range that produces <code>true</code></li>
              <li>[all other integers] : the range that produces <code>false</code></li>
            </ul>
          </tip-box>
          <tip-box>
            <p>üì¶ Some more examples:</p>
            <table class="table">
              <tr>
                <th>Specification</th>
                <th>Equivalence partitions</th>
              </tr>
              <tr>
                <td>
                  <p><code>isValidFlag(String s): boolean</code><br> Returns <code>true</code> if s is one of [<code>&quot;F&quot;</code>, <code>&quot;T&quot;</code>, <code>&quot;D&quot;</code>]. The comparison is case-sensitive.</p>
                </td>
                <td>
                  <p>[<code>&quot;F&quot;</code>] [<code>&quot;T&quot;</code>] [<code>&quot;D&quot;</code>] [<code>&quot;f&quot;</code>, <code>&quot;t&quot;</code>, <code>&quot;d&quot;</code>] [any other string][null]</p>
                </td>
              </tr>
              <tr>
                <td>
                  <p><code>squareRoot(String s): int</code><br> Pre-conditions: s represents a positive integer<br> Returns the square root of <code>s</code> if the square root is an integer; returns <code>0</code> otherwise.</p>
                </td>
                <td>
                  <p>[<code>s</code> is not a valid number] [<code>s</code> is a negative integer] [<code>s</code> has an integer square root] [<code>s</code> does not have an integer square root]</p>
                </td>
              </tr>
            </table>
          </tip-box>
        </div>
      </div>
      <div>
        <div>
          <h4 id="intermediate-two">Intermediate <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p>When deciding EPs of OOP methods, we need to identify EPs of all data participants that can potentially influence the behaviour of the method, such as,</p>
          <ul>
            <li>the target object of the method call</li>
            <li>input parameters of the method call</li>
            <li>other data/objects accessed by the method such as global variables. This category may not be applicable if using the black box approach (because the test case designer using the black box approach will not know how the method is implemented)</li>
          </ul>
          <tip-box>
            <p>üì¶ Consider this method in the <code>DataStack</code> class:
              <code>push(Object o): boolean</code></p>
            <ul>
              <li>Adds o to the top of the stack if the stack is not full.</li>
              <li>returns <code>true</code> if the push operation was a success.</li>
              <li>throws
                <ul>
                  <li><code>MutabilityException</code> if the global flag <code>FREEZE==true</code>.</li>
                  <li><code>InvalidValueException</code> if o is null.</li>
                </ul>
              </li>
            </ul>
            <p>EPs:</p>
            <ul>
              <li><code>DataStack</code> object: [full] [not full]</li>
              <li><code>o</code>: [null] [not null]</li>
              <li><code>FREEZE</code>: [true][false]</li>
            </ul>
          </tip-box>
          <tip-box>
            <p>üì¶ Consider a simple Minesweeper app. What are the EPs for the <code>newGame()</code> method of the <code>Logic</code> component?</p>
            <p>As <code>newGame()</code> does not have any parameters, the only obvious participant is the <code>Logic</code> object itself.</p>
            <p>Note that if the glass-box or the grey-box approach is used, other associated objects that are involved in the method might also be included as participants. For example, <code>Minefield</code> object can be considered as another participant
              of the <code>newGame()</code> method. Here, the black-box approach is assumed.</p>
            <p>Next, let us identify equivalence partitions for each participant. Will the <code>newGame()</code> method behave differently for different <code>Logic</code> objects? If yes, how will it differ? In this case, yes, it might behave differently
              based on the game state. Therefore, the equivalence partitions are:</p>
            <ul>
              <li><code>PRE_GAME</code> : before the game starts, minefield does not exist yet</li>
              <li><code>READY</code> : a new minefield has been created and waiting for player‚Äôs first move</li>
              <li><code>IN_PLAY</code> : the current minefield is already in use</li>
              <li><code>WON</code>, <code>LOST</code> : let us assume the <code>newGame</code> behaves the same way for these two values</li>
            </ul>
          </tip-box>
          <tip-box>
            <p>üì¶ Consider the <code>Logic</code> component of the Minesweeper application. What are the EPs for the <code>markCellAt(int x, int y)</code> method?. The partitions in <strong>bold</strong> represent valid inputs.</p>
            <ul>
              <li><code>Logic</code>: PRE_GAME, <strong>READY</strong>, <strong>IN_PLAY</strong>, WON, LOST</li>
              <li><code>x</code>: [MIN_INT..-1] <strong>[0..(W-1)]</strong> [W..MAX_INT] <span class="dimmed">(we assume a minefield size of WxH)</span></li>
              <li><code>y</code>: [MIN_INT..-1] <strong>[0..(H-1)]</strong> [H..MAX_INT]</li>
              <li><code>Cell</code> at <code>(x,y)</code>: <strong>HIDDEN</strong>, MARKED, CLEARED</li>
            </ul>
          </tip-box>
        </div>
      </div>
      <h2 id="boundary-value-analysis">Boundary Value Analysis</h2>
      <div>
        <div>
          <h4 id="what-one-5">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0031-20e3.png"></h4>
        </div>
        <div>
          <p><strong><em>Boundary Value Analysis (BVA)</em> is test case design heuristic that is based on the observation that bugs often result from incorrect handling of boundaries of equivalence partitions.</strong> This is not surprising, as the end
            points of the boundary are often used in branching instructions etc. where the programmer can make mistakes.</p>
          <tip-box>
            <p>üì¶ <code>markCellAt(int x, int y)</code> operation could contain code such as if <code>(x &gt; 0 &amp;&amp; x &lt;= (W-1))</code> which involves boundaries of x‚Äôs equivalence partitions.</p>
          </tip-box>
          <p><strong>BVA suggests that when picking test inputs from an equivalence partition, values near boundaries (i.e. boundary values) are more likely to find bugs.</strong></p>
          <p>Boundary values are sometimes called <em>corner cases</em>.</p>
        </div>
      </div>
      <div>
        <div>
          <h4 id="how-two">How <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p><strong>Typically, we choose three values around the boundary to test: one value from the boundary, one value just below the boundary, and one value just above the boundary.</strong> The number of values to pick depends on other factors, such
            as the cost of each test case.</p>
          <tip-box>
            <p>üì¶ Some examples:</p>
            <table class="table">
              <tr>
                <th>Equivalence partition</th>
                <th>Some possible boundary values</th>
              </tr>
              <tr>
                <td>
                  <p>[1-12]</p>
                </td>
                <td>
                  <p>0,1,2, 11,12,13</p>
                </td>
              </tr>
              <tr>
                <td>
                  <p>[MIN_INT, 0]<br>
                    <span class="dimmed">(MIN_INT is the minimum possible integer value allowed by the environment)</span></p>
                </td>
                <td>
                  <p>MIN_INT, MIN_INT+1, -1, 0 , 1</p>
                </td>
              </tr>
              <tr>
                <td>
                  <p>[any non-null String]</p>
                </td>
                <td>
                  <p>Empty String, a String of maximum possible length</p>
                </td>
              </tr>
              <tr>
                <td>
                  <p>[prime numbers]<br> [‚ÄúF‚Äù]
                    <br> [‚ÄúA‚Äù, ‚ÄúD‚Äù, ‚ÄúX‚Äù]</p>
                </td>
                <td>
                  <p>No specific boundary<br> No specific boundary<br> No specific boundary</p>
                </td>
              </tr>
              <tr>
                <td>
                  <p>[non-empty Stack]<br>
                    <span class="dimmed">(we assume a fixed size stack)</span></p>
                </td>
                <td>
                  <p>Stack with: one element, two elements, no empty spaces, only one empty space</p>
                </td>
              </tr>
            </table>
          </tip-box>
        </div>
      </div>
      <p style="page-break-after: always;">&nbsp;</p>
      <h1 id="quality-assurance">Quality Assurance</h1>
      <h2 id="introduction-2">Introduction</h2>
      <div>
        <div>
          <h4 id="what-one-6">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0031-20e3.png"></h4>
        </div>
        <div>
          <p><strong>Software <em>Quality Assurance</em> (QA) is the process of ensuring that the software being built has the required levels of quality.</strong></p>
          <p>While testing is the most common activity used in QA, there are other complementary techniques such as <em>static analysis, code reviews,</em> and <em>formal verification</em>.</p>
        </div>
      </div>
      <div>
        <div>
          <h4 id="validation-vs-verification-two">Validation vs Verification <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p><strong>Quality Assurance = Validation + Verification</strong></p>
          <p>QA involves checking two aspects:</p>
          <ol>
            <li>Validation: are we <em>building the right system</em> i.e., are the requirements correct?</li>
            <li>Verification: are we <em>building the system right</em> i.e., are the requirements implemented correctly?</li>
          </ol>
          <p>Whether something belongs under validation or verification is not that important. What is more important is both are done, instead of limiting to verification (i.e., remember that the requirements can be wrong too).</p>
        </div>
      </div>
      <h2 id="code-reviews">Code Reviews</h2>
      <div>
        <div>
          <h4 id="what-one-7">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0031-20e3.png"></h4>
        </div>
        <div>
          <p><strong>Code review is the systematic examination code with the intention of finding where the code can be improved.</strong></p>
          <p>Reviews can be done in various forms. Some examples below:</p>
          <ul>
            <li>
              <p><strong>In <trigger trigger="click" for="modal:codeReview-pairProgramming">pair programming</trigger></strong></p>
              <ul>
                <li>As pair programming involves two programmers working on the same code at the same time, there is an implicit review of the code by the other member of the pair.</li>
              </ul>
            </li>
          </ul>
          <modal large="" title="Pair Programming" id="modal:codeReview-pairProgramming">
            <tip-box type="definition">
              <div>
                <p><strong>Pair Programming</strong>:</p>
                <blockquote>
                  <p>Pair programming is an agile software development technique in which two programmers work together at one workstation. One, the driver, writes code while the other, the observer or navigator, reviews each line of code as it is typed
                    in. The two programmers switch roles frequently. <sub>[<a href="https://en.wikipedia.org/wiki/Pair_programming">source: Wikipedia</a>]</sub></p>
                </blockquote>
              </div>
            </tip-box>
            <p><img src="https://upload.wikimedia.org/wikipedia/commons/a/af/Pair_programming_1.jpg" width="400"><br>
              <sub>[<a href="https://en.wikipedia.org/wiki/Pair_programming">image credit: Wikipedia</a>]</sub></p>
            <p>üì∫ A good introduction to pair programming:</p>
            <div class="block-embed block-embed-service-youtube"><iframe type="text/html" src="//www.youtube.com/embed/ET3Q6zNK3Io" frameborder="0" width="640" height="390" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen></iframe></div>
          </modal>
          <ul>
            <li>
              <p><strong>Pull Request reviews</strong></p>
              <ul>
                <li>Project Management Platforms such as GitHub and BitBucket allows the new code to be proposed as Pull Requests and provides the ability for others to review the code in the PR.</li>
              </ul>
            </li>
            <li>
              <p><strong>Formal inspections</strong></p>
              <ul>
                <li>
                  <p>Inspections involve a group of people systematically examining a project artifacts to discover defects. Members of the inspection team play various roles during the process, such as:</p>
                  <ul>
                    <li>the author - the creator of the artifact</li>
                    <li>the moderator - the planner and executor of the inspection meeting</li>
                    <li>the secretary - the recorder of the findings of the inspection</li>
                    <li>the inspector/reviewer - the one who inspects/reviews the artifact.</li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
          <p>Advantages of code reviews over testing:</p>
          <ul>
            <li>It can detect functionality defects as well as other problems such as coding standard violations.</li>
            <li>Can verify non-code artifacts and incomplete code</li>
            <li>Do not require test drivers or stubs.</li>
          </ul>
          <p>Disadvantages:</p>
          <ul>
            <li>It is a manual process and therefore, error prone.</li>
          </ul>
        </div>
      </div>
      <h2 id="static-analysis">Static Analysis</h2>
      <div>
        <div>
          <h4 id="what-two-5">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <tip-box type="definition">
            <div>
              <p><strong>Static analysis</strong>: Static analysis is the analysis of code without actually executing the code.</p>
            </div>
          </tip-box>
          <p>Static analysis of code can find useful information such unused variables, unhandled exceptions, style errors, and statistics. Most modern IDEs come with some inbuilt static analysis capabilities. For example, an IDE can highlight unused variables
            as you type the code into the editor.</p>
          <p>Higher-end static analyzer tools can perform for more complex analysis such as locating potential bugs, memory leaks, inefficient code structures etc.</p>
          <tip-box>
            <p>üì¶ Some example static analyzer for Java:</p>
            <ul>
              <li><a href="http://checkstyle.sourceforge.net/">CheckStyle</a></li>
              <li><a href="http://findbugs.sourceforge.net/">PMD</a></li>
              <li><a href="https://pmd.github.io/">FindBugs</a></li>
            </ul>
          </tip-box>
          <p><em>Linters</em> are a subset of static analyzers that specifically aim to locate areas where the code can be made 'cleaner'.</p>
        </div>
      </div>
      <h2 id="formal-verification">Formal Verification</h2>
      <div>
        <div>
          <h4 id="what-two-6">What <img style="height: 1em;width: 1em;margin: 0 .05em 0 .1em;vertical-align: -0.1em;" src="https://assets-cdn.github.com/images/icons/emoji/unicode/0032-20e3.png"></h4>
        </div>
        <div>
          <p><strong>Formal verification uses mathematical techniques to prove the correctness of a program.</strong></p>
          <panel type="seamless" header=":tv: An introduction to Formal Methods">
            <div class="block-embed block-embed-service-youtube"><iframe type="text/html" src="//www.youtube.com/embed/89fKiaMxHrA" frameborder="0" width="640" height="390" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen></iframe></div>
            <p>by <a href="http://www.cs.utoronto.ca/~hehner/">Eric Hehner</a></p>
            <p></p>
          </panel>
          <p></p>
          <p>Advantages:</p>
          <ul>
            <li><strong>Formal verification can be used to prove the absence of errors</strong>. In contrast, testing can only prove the presence of error, not their absence.</li>
          </ul>
          <p>Disadvantages:</p>
          <ul>
            <li>It only proves the compliance with the specification, but not the actual utility of the software.</li>
            <li>It requires highly specialized notations and knowledge which makes it an expensive technique to administer. Therefore, <strong>formal verifications are more commonly used in safety-critical software such as flight control systems</strong>.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
</div>
</body>
<script src="..\..\markbind\js\vue.min.js"></script>
<script src="..\..\markbind\js\vue-strap.min.js"></script>
<script src="..\..\markbind\js\setup.js"></script>
</html>
